# Методологія та методи Data Science
У процесі Data Science використовується низка методів і підходів, які застосовуються на різних етапах роботи з даними. Цей процес включає від визначення проблеми до моделювання, оцінки й впровадження рішень. Розглянемо кожен етап докладніше з поясненням відповідних методів та підходів.

## 1. Визначення проблеми
На цьому етапі формується дослідницька або бізнес-проблема, яка потребує вирішення за допомогою даних. Визначаються мета проекту, ключові показники ефективності (KPI) та критерії успіху.

- Приклад задачі: Прогнозування відтоку клієнтів у банку.
- Методи:
  - Формулювання проблеми як задачі класифікації, регресії або кластеризації.
- Підходи:
  - Співпраця з експертами галузі для уточнення бізнес-контексту та визначення цілей проекту.

## 2. Збір та обробка даних
Після визначення проблеми відбувається збір даних з різних джерел, таких як бази даних, API, веб-скрапінг або хмарні сервіси. Очищення та підготовка даних є важливим кроком для забезпечення якості аналізу.

- Приклад задачі: Збір даних про продажі з CRM-системи.
- Методи:
  - Очищення даних: Видалення пропущених значень, аномалій, дублікатів.
  - Перетворення даних: Нормалізація, стандартизація, кодування категоріальних змінних (one-hot encoding).
- Підходи:
  - Використання Pandas та NumPy для обробки даних.
  - Застосування SQL для отримання даних з реляційних баз.
  - Використання веб-скрапінгу (BeautifulSoup, Scrapy) для витягнення даних із сайтів.

## 3. Аналіз даних та інженерія ознак
На цьому етапі здійснюється детальний аналіз даних для виявлення закономірностей і залежностей. Інженерія ознак (feature engineering) передбачає створення нових ознак (фіч) для покращення моделей.

- Приклад задачі: Аналіз факторів, що впливають на поведінку покупців.
- Методи:
  - Описова статистика: Обчислення середнього, медіани, стандартного відхилення для основного розуміння розподілу даних.
  - Кореляційний аналіз: Виявлення залежностей між змінними.
  - Інженерія ознак: Створення нових змінних на основі вже наявних (наприклад, витрати часу на сайті).
- Підходи:
  - Візуалізація даних із допомогою бібліотек Matplotlib і Seaborn (гістограми, теплові карти для візуалізації кореляцій).
  - Застосування PCA (Principal Component Analysis) для зменшення розмірності даних.

## 4. Моделювання
Побудова моделі для прогнозування або класифікації є центральною частиною Data Science. Залежно від типу задачі вибирається відповідна модель.

- Приклад задачі: Прогнозування ймовірності купівлі продукту.
- Методи:
  - Супервізоване навчання: Використовується для задач, де є мітки (labels). Приклади методів:
    - Лінійна та логістична регресія (для регресії та класифікації відповідно).
    - Дерева рішень (Decision Trees), Random Forest для складніших моделей класифікації.
    - Нейронні мережі для глибокого навчання (deep learning).
  - Несупервізоване навчання: Застосовується до даних без міток:
    - Кластеризація (K-Means, DBSCAN).
    - Метод головних компонент (PCA) для аналізу прихованих закономірностей.
Підходи:
  - Вибір моделі залежно від типу даних та мети (класифікація, регресія, кластеризація).
  - Підготовка навчальних та тестових вибірок для навчання моделей.

## 5. Оцінка моделі та її вдосконалення
Після побудови моделі її необхідно оцінити, щоб визначити, наскільки добре вона працює на нових даних. Застосовуються різні метрики для оцінки продуктивності моделей.

- Приклад задачі: Оцінка точності моделі прогнозування ризику дефолту клієнта.
- Методи:
  - Метрики оцінки:
    - Accuracy (точність), Precision (точність), Recall (повнота), F1-score для класифікаційних моделей.
    - Mean Squared Error (MSE) для регресійних задач.
  - Перехресна валідація (cross-validation): Дозволяє оцінити модель на різних підмножинах даних для уникнення перенавчання.
  - Регуляризація: Використання L1 або L2 регуляризації для зменшення перенавчання.
- Підходи:
  - Оптимізація гіперпараметрів за допомогою Grid Search або Random Search.
  - Використання ансамблів моделей (bagging, boosting) для підвищення точності.

## 6. Інтерпретація результатів та впровадження
Інтерпретація результатів є важливою частиною для прийняття обґрунтованих рішень на основі моделі. Після цього рішення впроваджуються у реальні процеси.

- Приклад задачі: Побудова дашборду для відстеження ключових показників бізнесу.
- Методи:
  - Аналіз важливості ознак: Наприклад, використання коефіцієнтів регресії або показників важливості ознак у випадку дерев рішень.
  - Аналіз впливу змінних: Оцінка того, як різні змінні впливають на результат моделі.
- Підходи:
  - Візуалізація результатів у вигляді графіків, дашбордів для зручного сприйняття результатів іншими учасниками процесу.
  - Створення автоматизованих звітів за допомогою бібліотек, як-от Plotly, Dash.

## 7. Автоматизація та впровадження в продакшн
Останній етап передбачає автоматизацію процесу створення моделей, їхню інтеграцію у виробничі середовища, а також моніторинг продуктивності моделі у реальному часі.

- Приклад задачі: Автоматизація процесу рекомендацій продуктів для онлайн-магазину.
- Методи:
  - AutoML: Використання платформ автоматизації побудови моделей (наприклад, Google AutoML, H2O.ai).
  - CI/CD для моделей: Постійна інтеграція та безперервна доставка моделей у продакшн.
- Підходи:
  - Розгортання моделей через API (FastAPI, Flask) або використання спеціалізованих платформ (TensorFlow Serving, MLflow).
  - Моніторинг продуктивності моделей та оновлення у разі зниження точності.

## Висновок
Ця структура демонструє, як методологія та методи Data Science інтегруються у послідовний процес від визначення проблеми до автоматизації рішень. Кожен етап включає конкретні методи та підходи, які забезпечують глибоке розуміння даних та ефективне використання моделей для вирішення реальних задач.

# CRISP-DM (Cross-Industry Standard Process for Data Mining)
CRISP-DM – це одна з найпопулярніших методологій для управління проєктами з науки про дані та видобутку даних. Вона складається з шести етапів, які допомагають структурувати процес аналітики та побудови моделей. Ось ці етапи:

## 1. Розуміння бізнесу (Business Understanding)
- Мета: Визначити цілі проєкту з точки зору бізнесу.
- Опис: На цьому етапі визначаються бізнес-проблеми, ставляться конкретні питання та задачі, які необхідно вирішити. Це важливо для того, щоб отримані результати були корисними для бізнесу.
- Ключові дії:
  - Визначення бізнес-цілей і вимог.
  - Визначення основних критеріїв успіху для проєкту.

## 2. Розуміння даних (Data Understanding)
- Мета: Дослідити дані та визначити, наскільки вони придатні для вирішення бізнес-завдань.
- Опис: Аналітики досліджують наявні дані, оцінюють їхню якість, перевіряють наявність пропусків, відхилень і помилок.
- Ключові дії:
  - Збір вихідних даних.
  - Проведення початкового аналізу для виявлення патернів.
 -  Оцінка якості даних.
## 3. Підготовка даних (Data Preparation)
- Мета: Підготувати дані для моделювання.
- Опис: На цьому етапі аналітики здійснюють очищення даних, трансформації, вибір змінних для аналізу та перетворення у зручний формат.
- Ключові дії:
  - Очищення даних від відсутніх або некоректних значень.
  - Перетворення та нормалізація даних.
  - Створення нових характеристик (feature engineering).
## 4. Моделювання (Modeling)
- Мета: Створити та налаштувати моделі для вирішення поставлених задач.
- Опис: Вибираються та налаштовуються алгоритми для побудови прогнозних моделей. Модель може бути прогнозною, класифікаційною або дескриптивною.
- Ключові дії:
  - Вибір методів моделювання (наприклад, лінійна регресія, дерева рішень).
  - Оптимізація параметрів моделей.
  - Оцінка продуктивності моделей на навчальних і тестових даних.
## 5. Оцінка (Evaluation)
- Мета: Оцінити якість моделі та переконатися, що вона відповідає бізнес-завданням.
- Опис: Оцінюється продуктивність моделі за допомогою метрик (точність, відчутливість, специфічність). Також проводиться аналіз, наскільки добре модель вирішує бізнес-проблему.
- Ключові дії:
  - Перевірка точності моделі на нових даних.
     Вибір остаточної моделі на основі вимог бізнесу.
## 6. Розгортання (Deployment)
- Мета: Інтегрувати модель у реальне бізнес-середовище.
- Опис: Модель впроваджується в бізнес-процеси для отримання реальних результатів. Розгортання може включати створення інструментів або додатків для бізнес-користувачів, які використовуватимуть модель.
- Ключові дії:
  - Підготовка звітів для бізнес-користувачів.
  - Розгортання моделі в оперативних системах.
  - Моніторинг та підтримка роботи моделі.

CRISP-DM – це ітеративна методологія, де можливі повернення на попередні етапи для вдосконалення процесу.

# Методологія Джона Роллінза
Джон Роллінз є автором концепції методології Data Science для підприємств. Основною ідеєю його підходу є створення надійних і масштабованих моделей, які інтегровані у бізнес-процеси компанії. Методологія має кілька основних принципів і етапів.

## Основні принципи методології Джона Роллінса
- **Циклічність**: Методологія є ітеративною, що дозволяє повертатися до попередніх етапів у разі необхідності.
- **Організація**: Чітка структура, яка забезпечує послідовність та узгодженість на всіх етапах.
- **Гнучкість**: Можливість адаптації до різних бізнес-сценаріїв та специфічних вимог.
- **Співпраця**: Активна участь зацікавлених сторін на всіх етапах процесу.

## Основні етапи методології
### 1. Розуміння бізнесу

  - Визначення бізнес-проблеми.
  - Ідентифікація даних, необхідних для вирішення основного бізнес-питання.

### 2. Аналітичний підхід

  - Вибір аналітичного підходу: описовий, діагностичний, прогностичний чи прескриптивний.
  - Рішення про використання методів машинного навчання.

### 3. Вимоги до даних

  - Визначення потрібного змісту, форматів та джерел даних для аналітичного підходу.

### 4. Збір даних

  - Оцінка якості та кількості зібраних даних.
  - Використання описової статистики та візуалізації для оцінки даних.

### 5. Розуміння даних

  - Аналіз зібраних даних для визначення їх відповідності бізнес-проблемі.
  - Використання статистичних показників, таких як середнє, медіана, стандартне відхилення тощо.

### 6. Підготовка даних

  - Виявлення відсутніх чи неправильних значень, видалення дублікатів.
  - Інженерія ознак та текстовий аналіз для перевірки даних.

### 7. Моделювання

  - Використання навчального набору даних для побудови моделі.
  - Тестування кількох алгоритмів для визначення відповідності змінних бізнес-питанням.

### 8. Оцінка моделі

  - Діагностичні заходи для перевірки якості моделі.
  - Оцінка статистичної значущості та відповідності моделі бізнес-питанням.

### 9. Розгортання

  - Надання моделі зацікавленим сторонам (власникам рішень, маркетологам, розробникам).
  - Переконання, що модель може бути використана на практиці.

### 10. Зворотний зв'язок

  - Оцінка продуктивності моделі зацікавленими сторонами.
  - Внесення коректив на основі отриманих відгуків для покращення моделі.

Цінність моделі даних залежить від її здатності до ітерацій, тобто від того, наскільки успішно вона враховує відгуки користувачів. Цей підхід забезпечує постійне вдосконалення та адаптацію до змінюваних бізнес-вимог.
