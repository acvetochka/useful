# Tools for Data Science

## 1. Основні мови програмування в Data Science
### 1.1. Python
Python є найпопулярнішою мовою для Data Science завдяки своїй простоті та великій кількості бібліотек, що полегшують роботу з даними. Основні його переваги:

- Широкий спектр бібліотек: `Pandas`, `NumPy`, `SciPy`, `scikit-learn`, `Matplotlib`, `Seaborn`, `TensorFlow`, `Keras`, `PyTorch`, `StatsModels` та інші.
- Машинне навчання: Python часто використовується для побудови моделей машинного навчання з використанням бібліотек на зразок `scikit-learn`, `TensorFlow`, `Keras`, `PyTorch`.
- Аналіз даних: `Pandas` і `NumPy` дозволяють ефективно обробляти та аналізувати великі набори даних.
- Візуалізація: `Matplotlib` і `Seaborn` дають змогу створювати діаграми та графіки, що полегшує візуальне представлення даних.

### 1.2. R
R – це мова програмування, спеціально створена для статистичних обчислень і аналізу даних. Її використовують для:

- Статистичного аналізу: Робота з великими наборами даних і статистичними моделями (пакети `dplyr`, `tidyr`).
- Візуалізація: R має потужні бібліотеки для графіків, такі як `ggplot2`, що дозволяють створювати професійні візуалізації даних.
- Моделі: R має багатий набір інструментів для статистичного моделювання, як-от лінійна регресія, кластеризація та інші.

### 1.3. SQL
SQL (Structured Query Language) використовується для роботи з реляційними базами даних:

- Отримання даних: SQL допомагає виконувати запити до баз даних і витягувати потрібну інформацію з великих структурованих наборів даних.
- Обробка даних: У SQL можна виконувати складні операції фільтрації, об’єднання, агрегації та сортування даних.

### 1.4. Julia
Julia – це мова, яка набуває популярності в Data Science, завдяки своїй швидкості й можливостям:

- Висока продуктивність: Julia конкурує з C/C++ у швидкості виконання.
- Обчислювальні задачі: Використовується в задачах, де важлива висока продуктивність, таких як моделювання та симуляції.

### 1.5. Scala
Scala часто використовується в поєднанні з платформою Apache Spark для обробки великих даних (Big Data):

- Big Data та Spark: Scala – основна мова для написання програм під Apache Spark, що дозволяє обробляти величезні масиви даних у розподілених системах.


## 2. Бібліотеки та інструменти для Data Science
### 2.1. Бібліотеки для обробки даних
- `Pandas` (Python): Використовується для роботи з таблицями та обробки структурованих даних. Має інструменти для маніпуляції таблицями, фільтрації даних і їх агрегації.
- `NumPy` (Python): Бібліотека для роботи з багатовимірними масивами даних і виконання математичних операцій.
- `Dplyr` (R): Подібний до Pandas пакет для роботи з даними в R, забезпечує зручну маніпуляцію з таблицями.
- `Tidyr` (R): Призначений для обробки й очищення даних у R.

### 2.2. Бібліотеки для візуалізації даних
- `Matplotlib` (Python): Основна бібліотека для створення графіків і діаграм у Python.
- `Seaborn` (Python): Розширення Matplotlib для більш якісної та інформативної візуалізації статистичних даних.
- `ggplot2` (R): Потужна бібліотека для візуалізації даних в R.
- `Plotly` (Python, R): Бібліотека для створення інтерактивних графіків.

### 2.3. Бібліотеки для машинного навчання
- `scikit-learn` (Python): Одна з найпопулярніших бібліотек для машинного навчання, що підтримує велику кількість алгоритмів (лінійна регресія, класифікація, кластеризація, дерева рішень, ансамблі).
- `TensorFlow` (Python): Фреймворк для створення нейронних мереж і моделей глибокого навчання.
- `Keras` (Python): Спрощує побудову нейронних мереж на базі TensorFlow.
- `PyTorch` (Python): Альтернатива TensorFlow, популярна завдяки своїй простоті й зручності для дослідницьких цілей.
- `XGBoost` (Python, R): Спеціалізується на градієнтному бустингу для задач класифікації й регресії.

### 2.4. Інструменти для роботи з Big Data
- `Apache Spark`: Платформа для обробки великих масивів даних у розподілених системах. Має API для Python, Scala та інших мов.
- `Hadoop`: Система для зберігання й обробки великих даних із використанням розподілених обчислень.

## 3. Середовища розробки для Data Science
### 3.1. Jupyter Notebook
Одне з найпопулярніших середовищ для написання й виконання коду в Data Science:

- Інтерактивні дослідження: Підтримує Python та інші мови, дозволяє виконувати код блоками й одразу отримувати результати.
- Візуалізація: Підтримує інтерактивні графіки прямо в середовищі.
- Документація: Дає змогу писати пояснення й коментарі разом із кодом, що полегшує спільну роботу.

### 3.2. RStudio
Спеціалізоване середовище для роботи з мовою R:

- Підтримка R: Зручне середовище для роботи з R, що включає консоль, редактор скриптів і можливість створення RMarkdown документів.
- Інтеграція з візуалізацією: Дає змогу створювати й переглядати графіки в процесі написання коду.

### 3.3. Spyder
Spyder – це IDE для Python, яка орієнтована на наукові дослідження й обробку даних. Основні можливості:

- Інтеграція з бібліотеками: Підтримка Pandas, NumPy, Matplotlib, scikit-learn та інших бібліотек.
- Інтерактивний режим: Дає змогу виконувати код поетапно й аналізувати результат.

### 3.4. VS Code
Універсальне середовище розробки, яке також можна налаштувати для роботи в Data Science:

- Розширення для Data Science: Плагіни для підтримки Jupyter, інтеграції з Python, робота з візуалізацією даних.
- Інтерактивне програмування: Можливість роботи з блоками коду й відображення результатів.

### 3.5. Google Colab
Хмарне середовище для виконання Python-коду:

- Доступ до GPU: Підтримує запуск машинного навчання на GPU або TPU безкоштовно.
- Інтеграція з Google Drive: Дозволяє легко зберігати файли в хмарі й ділитися ними.

## 4. Інструменти для керування проєктами та спільної роботи
- `Git/GitHub`: Система контролю версій, що дозволяє керувати кодом і співпрацювати в командах.
- `Docker`: Використовується для створення контейнеризованих середовищ, що забезпечує відтворюваність експериментів і моделей.
- `MLflow`: Платформа для керування життєвим циклом машинного навчання – від навчання моделей до їх розгортання.

## 5. API, набори даних та моделі в Data Science

### 5.1. Популярні API для роботи з даними
- Google API:

  - `Google Cloud BigQuery`: Потужна платформа для обробки великих даних, яка дозволяє працювати з великими наборами даних у хмарі, виконувати запити на SQL та інтегрувати дані з іншими Google-сервісами.
  - `Google Sheets API`: Дозволяє автоматизувати роботу з Google Таблицями, отримувати й завантажувати дані через Python, R або інші мови.

- Twitter API:

  - `Twitter API`: Дає можливість отримувати та аналізувати твіти у реальному часі, що корисно для збору даних про настрої або інші соціальні сигнали.

- Kaggle API:

  - `Kaggle API`: Забезпечує доступ до великої кількості готових наборів даних, дозволяє автоматизувати завантаження даних та керування проєктами через інтерфейс командного рядка.

### 5.2. Популярні набори даних для Data Science
Набори даних є основою будь-якого Data Science-проєкту, і їх часто використовують для тренування моделей, тестування гіпотез або навчання.

- `Iris Dataset`: Один із найпопулярніших навчальних наборів даних для класифікації квітів на основі параметрів. Використовується для тестування базових алгоритмів машинного навчання.
- `MNIST`: Набір зображень рукописних цифр (28x28 пікселів), широко використовуваний для задач класифікації в нейронних мережах та інших моделях машинного навчання.
- `CIFAR-10`: Набір зображень, який містить 60 тисяч малюнків 10 класів (коти, машини тощо). Використовується для навчання моделей зображень і комп'ютерного зору.
- `Boston Housing Dataset`: Набір даних про ціни на житло в Бостоні, часто використовуваний для задач регресії, передбачення цін на основі різних характеристик будинків.
- `Titanic Dataset`: Відомий набір даних про пасажирів «Титаніка», використовуваний для задач класифікації на основі виживання.
- `COCO Datase`t: Набір зображень із позначеними об'єктами для задач комп'ютерного зору, таких як сегментація об'єктів і розпізнавання.

### 5.3. Моделі машинного навчання
- Моделі для класифікації:

  - `Логістична регресія`: Використовується для бінарної класифікації (напр., вижив чи не вижив пасажир Титаніка).
  - `Класичні алгоритми класифікації`: SVM (Support Vector Machine), K-Nearest Neighbors, Random Forest, Naive Bayes.
  - `Нейронні мережі`: Використовуються для класифікації зображень, розпізнавання мови та інших складних задач.

- Моделі для регресії:

  - `Лінійна регресія`: Проста модель для передбачення кількісних значень.
  - Ридж-регресія (`Ridge Regression`) і Лассо-регресія (`Lasso Regression`): Поліпшені версії лінійної регресії, що допомагають уникнути перенавчання та враховують багатоколінеарність.
  - `XGBoost` і `LightGBM`: Підходять для задач регресії та класифікації, показують високі результати на багатьох типах даних.

- Моделі для кластеризації:

  - `K-Means`: Один із найпоширеніших алгоритмів кластеризації, що використовує відстані між точками для створення груп.
  - `DBSCAN`: Алгоритм для виявлення кластерів будь-якої форми, стійкий до шуму.

- Моделі для глибокого навчання:

  - `Convolutional Neural Networks` (CNNs): Спеціалізовані на обробці зображень.
  - `Recurrent Neural Networks` (RNNs): Використовуються для обробки послідовностей даних, таких як часові ряди або тексти.
  - `Generative Adversarial Networks` (GANs): Моделі для генерації нових зразків даних на основі навчальних наборів.

### 5.4. Фреймворки для моделювання
- `TensorFlow`: Фреймворк для створення моделей машинного й глибокого навчання. Дозволяє ефективно працювати з нейронними мережами та використовувати апаратні прискорювачі (GPU, TPU).
- `PyTorch`: Альтернатива TensorFlow, популярна завдяки своїй простоті й зручності. Часто використовується для наукових досліджень.
- `Keras`: Високорівнева обгортка для TensorFlow, що спрощує створення й навчання моделей.
- `H2O.ai`: Автоматизована платформа для машинного навчання, яка підтримує алгоритми регресії, класифікації та кластеризації.
- `Apache Mahout`: Фреймворк для масштабованих алгоритмів машинного навчання, призначений для роботи з великими даними.

## 6. Автоматизація роботи з моделями
- `MLflow`: Платформа для управління життєвим циклом машинного навчання (навчання, налаштування, відстеження експериментів і розгортання моделей).
- `Kubeflow`: Інструмент для автоматизації машинного навчання в Kubernetes. Дозволяє масштабувати процес навчання моделей і автоматично розгортати їх у виробничих середовищах.
